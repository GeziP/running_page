#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è¿åŠ¨æ•°æ®åˆ†æç”Ÿæˆå™¨
ç”Ÿæˆå„ç§ç»Ÿè®¡åˆ†ææ•°æ®ï¼Œæ”¯æŒæŒ‰æ´»åŠ¨ç±»å‹åˆ†ç±»
"""

import argparse
import json
import os
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from generator import Generator
from analysis import ActivityTypeManager, BasicStatsAnalyzer, AdvancedStatsAnalyzer
from config import SQL_FILE


def load_activities_from_db():
    """ä»æ•°æ®åº“åŠ è½½æ´»åŠ¨æ•°æ®"""
    try:
        generator = Generator(SQL_FILE)
        activities_list = generator.load()
        print(f"âœ… æˆåŠŸåŠ è½½ {len(activities_list)} æ¡æ´»åŠ¨è®°å½•")
        return activities_list
    except Exception as e:
        print(f"âŒ åŠ è½½æ´»åŠ¨æ•°æ®å¤±è´¥: {e}")
        return []


def ensure_output_dir():
    """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
    output_dir = Path("src/static/analysis")
    output_dir.mkdir(parents=True, exist_ok=True)
    return output_dir


def generate_activity_types(activities, output_dir):
    """ç”Ÿæˆæ´»åŠ¨ç±»å‹ç»Ÿè®¡"""
    print("ğŸ“Š ç”Ÿæˆæ´»åŠ¨ç±»å‹ç»Ÿè®¡...")

    type_manager = ActivityTypeManager()
    type_stats = type_manager.get_type_statistics(activities)

    # è·å–å¯ç”¨çš„æ´»åŠ¨ç±»å‹
    available_types = type_manager.get_available_types(activities)

    output_data = {
        "generated_at": datetime.now().isoformat(),
        "total_activities": len(activities),
        "available_types": available_types,
        "type_statistics": type_stats,
    }

    output_file = output_dir / "activity_types.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… æ´»åŠ¨ç±»å‹ç»Ÿè®¡å·²ä¿å­˜åˆ°: {output_file}")
    return type_stats


def generate_basic_statistics(activities, output_dir):
    """ç”ŸæˆåŸºç¡€ç»Ÿè®¡åˆ†æ"""
    print("ğŸ“ˆ ç”ŸæˆåŸºç¡€ç»Ÿè®¡åˆ†æ...")

    type_manager = ActivityTypeManager()
    stats_analyzer = BasicStatsAnalyzer()

    # è·å–å¯ç”¨çš„æ´»åŠ¨ç±»å‹
    available_types = ["all"] + type_manager.get_available_types(activities)

    all_stats = {}

    for activity_type in available_types:
        print(
            f"  å¤„ç†æ´»åŠ¨ç±»å‹: {type_manager.type_names.get(activity_type, activity_type)}"
        )

        # å‘¨æœŸæ€§ç»Ÿè®¡
        weekly_stats = stats_analyzer.calculate_period_stats(
            activities, "weekly", activity_type
        )
        monthly_stats = stats_analyzer.calculate_period_stats(
            activities, "monthly", activity_type
        )
        yearly_stats = stats_analyzer.calculate_period_stats(
            activities, "yearly", activity_type
        )

        # è·ç¦»åˆ†å¸ƒ
        distance_dist = stats_analyzer.calculate_distance_distribution(
            activities, activity_type
        )

        # ä¸ªäººæœ€ä½³è®°å½•
        personal_bests = stats_analyzer.get_personal_bests(activities, activity_type)

        all_stats[activity_type] = {
            "weekly": weekly_stats,
            "monthly": monthly_stats,
            "yearly": yearly_stats,
            "distance_distribution": distance_dist,
            "personal_bests": personal_bests,
        }

    output_data = {
        "generated_at": datetime.now().isoformat(),
        "stats_by_type": all_stats,
    }

    output_file = output_dir / "basic_statistics.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… åŸºç¡€ç»Ÿè®¡åˆ†æå·²ä¿å­˜åˆ°: {output_file}")
    return all_stats


def generate_advanced_analysis(activities, output_dir):
    """ç”Ÿæˆé«˜çº§åˆ†ææ•°æ®"""
    print("ğŸ”¬ ç”Ÿæˆé«˜çº§åˆ†ææ•°æ®...")

    type_manager = ActivityTypeManager()
    advanced_analyzer = AdvancedStatsAnalyzer()

    # è·å–å¯ç”¨çš„æ´»åŠ¨ç±»å‹
    available_types = ["all"] + type_manager.get_available_types(activities)

    advanced_stats = {}

    for activity_type in available_types:
        if activity_type in ["running", "trail_running", "all"]:
            print(
                f"  åˆ†ææ´»åŠ¨ç±»å‹: {type_manager.type_names.get(activity_type, activity_type)}"
            )

            # é…é€Ÿè¶‹åŠ¿åˆ†æ
            pace_trends = advanced_analyzer.analyze_pace_trends(
                activities, activity_type
            )

            advanced_stats[activity_type] = {"pace_trends": pace_trends}

    output_data = {
        "generated_at": datetime.now().isoformat(),
        "advanced_stats_by_type": advanced_stats,
    }

    output_file = output_dir / "advanced_analysis.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… é«˜çº§åˆ†ææ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    return advanced_stats


def generate_recent_summary(activities, output_dir):
    """ç”Ÿæˆæœ€è¿‘æ´»åŠ¨æ‘˜è¦"""
    print("ğŸ“… ç”Ÿæˆæœ€è¿‘æ´»åŠ¨æ‘˜è¦...")

    stats_analyzer = BasicStatsAnalyzer()
    type_manager = ActivityTypeManager()

    available_types = ["all"] + type_manager.get_available_types(activities)

    summaries = {}

    for activity_type in available_types:
        # æœ€è¿‘7å¤©
        weekly_summary = stats_analyzer.calculate_period_stats(
            activities, "weekly", activity_type
        )

        # å½“æœˆ
        monthly_summary = stats_analyzer.calculate_period_stats(
            activities, "monthly", activity_type
        )

        # å½“å¹´
        yearly_summary = stats_analyzer.calculate_period_stats(
            activities, "yearly", activity_type
        )

        summaries[activity_type] = {
            "weekly": weekly_summary,
            "monthly": monthly_summary,
            "yearly": yearly_summary,
        }

    output_data = {
        "generated_at": datetime.now().isoformat(),
        "recent_summaries": summaries,
    }

    output_file = output_dir / "recent_summary.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… æœ€è¿‘æ´»åŠ¨æ‘˜è¦å·²ä¿å­˜åˆ°: {output_file}")
    return summaries


def generate_analysis_overview(activities, output_dir):
    """ç”Ÿæˆåˆ†ææ¦‚è§ˆ"""
    print("ğŸ” ç”Ÿæˆåˆ†ææ¦‚è§ˆ...")

    type_manager = ActivityTypeManager()

    # åŸºæœ¬ä¿¡æ¯
    total_activities = len(activities)
    available_types = type_manager.get_available_types(activities)
    type_stats = type_manager.get_type_statistics(activities)

    # æ—¶é—´èŒƒå›´
    dates = []
    for activity in activities:
        date_str = activity.get("start_date_local", "")
        if date_str:
            try:
                if "T" in date_str:
                    date = datetime.fromisoformat(date_str.replace("Z", "+00:00"))
                else:
                    date = datetime.strptime(date_str, "%Y-%m-%d")
                dates.append(date)
            except:
                continue

    date_range = {}
    if dates:
        dates.sort()
        date_range = {
            "earliest": dates[0].strftime("%Y-%m-%d"),
            "latest": dates[-1].strftime("%Y-%m-%d"),
            "total_days": (dates[-1] - dates[0]).days + 1,
        }

    # æ€»ä½“ç»Ÿè®¡
    total_distance = sum(float(a.get("distance", 0)) for a in activities) / 1000
    total_time = sum(
        type_manager._parse_time(a.get("moving_time", "0")) for a in activities
    )

    overview = {
        "generated_at": datetime.now().isoformat(),
        "overview": {
            "total_activities": total_activities,
            "available_types": available_types,
            "total_distance_km": round(total_distance, 2),
            "total_time_seconds": total_time,
            "total_time_formatted": type_manager.format_time(total_time),
            "date_range": date_range,
            "avg_distance_per_activity": (
                round(total_distance / total_activities, 2)
                if total_activities > 0
                else 0
            ),
            "avg_time_per_activity": (
                type_manager.format_time(total_time // total_activities)
                if total_activities > 0
                else "0:00"
            ),
        },
        "type_breakdown": type_stats,
    }

    output_file = output_dir / "analysis_overview.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(overview, f, ensure_ascii=False, indent=2)

    print(f"âœ… åˆ†ææ¦‚è§ˆå·²ä¿å­˜åˆ°: {output_file}")
    return overview


def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆè¿åŠ¨æ•°æ®åˆ†æ")
    parser.add_argument(
        "--type",
        choices=["all", "types", "basic", "advanced", "summary", "overview"],
        default="all",
        help="ç”Ÿæˆåˆ†æç±»å‹",
    )

    args = parser.parse_args()

    print("ğŸš€ å¼€å§‹ç”Ÿæˆè¿åŠ¨æ•°æ®åˆ†æ...")
    print(f"ğŸ“Š åˆ†æç±»å‹: {args.type}")

    # åŠ è½½æ´»åŠ¨æ•°æ®
    activities = load_activities_from_db()
    if not activities:
        print("âŒ æ²¡æœ‰æ´»åŠ¨æ•°æ®ï¼Œé€€å‡ºç¨‹åº")
        return 1

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = ensure_output_dir()

    try:
        if args.type in ["all", "types"]:
            generate_activity_types(activities, output_dir)

        if args.type in ["all", "basic"]:
            generate_basic_statistics(activities, output_dir)

        if args.type in ["all", "advanced"]:
            generate_advanced_analysis(activities, output_dir)

        if args.type in ["all", "summary"]:
            generate_recent_summary(activities, output_dir)

        if args.type in ["all", "overview"]:
            generate_analysis_overview(activities, output_dir)

        print("\nğŸ‰ æ‰€æœ‰åˆ†ææ•°æ®ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")

        return 0

    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆåˆ†ææ•°æ®æ—¶å‡ºé”™: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
