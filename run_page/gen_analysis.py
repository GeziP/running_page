#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è¿åŠ¨æ•°æ®åˆ†æç”Ÿæˆå™¨
ç”Ÿæˆå„ç§ç»Ÿè®¡åˆ†ææ•°æ®ï¼Œæ”¯æŒæŒ‰æ´»åŠ¨ç±»å‹åˆ†ç±»
"""

import argparse
import json
import os
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from generator import Generator
from analysis import ActivityTypeManager, BasicStatsAnalyzer, AdvancedStatsAnalyzer
from config import SQL_FILE


def load_activities_from_db():
    """ä»æ•°æ®åº“åŠ è½½æ´»åŠ¨"""
    print("... ä»æ•°æ®åº“åŠ è½½æ´»åŠ¨...")
    try:
        generator = Generator(SQL_FILE)
        activities_list = generator.load()
        print(f"âœ… æˆåŠŸåŠ è½½ {len(activities_list)} æ¡æ´»åŠ¨è®°å½•")
        return activities_list
    except Exception as e:
        print(f"âŒ åŠ è½½æ´»åŠ¨æ•°æ®å¤±è´¥: {e}")
        return []


def load_activities_from_json(file_path="src/static/activities.json"):
    """ç›´æ¥ä»JSONæ–‡ä»¶åŠ è½½æ´»åŠ¨"""
    print(f"âœ… ç›´æ¥ä» {file_path} åŠ è½½æ´»åŠ¨è®°å½•...")
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: {file_path} æ–‡ä»¶æœªæ‰¾åˆ°ã€‚")
        return []
    except json.JSONDecodeError:
        print(f"âŒ é”™è¯¯: è§£æ {file_path} æ–‡ä»¶æ—¶å‡ºé”™ã€‚")
        return []


def ensure_output_dir():
    """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
    # åŒæ—¶è¾“å‡ºåˆ° src å’Œ public ç›®å½•ï¼Œç¡®ä¿å¼€å‘å’Œç”Ÿäº§ç¯å¢ƒéƒ½èƒ½è®¿é—®
    src_output_dir = Path("src/static/analysis")
    public_output_dir = Path("public/static/analysis")

    src_output_dir.mkdir(parents=True, exist_ok=True)
    public_output_dir.mkdir(parents=True, exist_ok=True)

    return src_output_dir, public_output_dir


def generate_activity_types(activities, output_dirs):
    """ç”Ÿæˆæ´»åŠ¨ç±»å‹ç»Ÿè®¡"""
    print("ğŸ“Š ç”Ÿæˆæ´»åŠ¨ç±»å‹ç»Ÿè®¡...")

    type_manager = ActivityTypeManager()
    type_stats = type_manager.get_type_statistics(activities)

    # è·å–å¯ç”¨çš„æ´»åŠ¨ç±»å‹
    available_types = type_manager.get_available_types(activities)

    output_data = {
        "generated_at": datetime.now().isoformat(),
        "total_activities": len(activities),
        "available_types": available_types,
        "type_statistics": type_stats,
    }

    # å†™å…¥åˆ°ä¸¤ä¸ªç›®å½•
    for output_dir in output_dirs:
        output_file = output_dir / "activity_types.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… æ´»åŠ¨ç±»å‹ç»Ÿè®¡å·²ä¿å­˜åˆ°: {output_dirs[0]}")
    return type_stats


def generate_basic_statistics(activities, output_dirs):
    """ç”ŸæˆåŸºç¡€ç»Ÿè®¡åˆ†æ"""
    print("ğŸ“ˆ ç”ŸæˆåŸºç¡€ç»Ÿè®¡åˆ†æ...")

    type_manager = ActivityTypeManager()
    stats_analyzer = BasicStatsAnalyzer()

    # è·å–å¯ç”¨çš„æ´»åŠ¨ç±»å‹
    available_types = ["all"] + type_manager.get_available_types(activities)
    print(f"  [DEBUG] å‘ç°çš„å¯ç”¨æ´»åŠ¨ç±»å‹: {available_types}")

    all_stats = {}

    for activity_type in available_types:
        print(
            f"  æ­£åœ¨å¤„ç†æ´»åŠ¨ç±»å‹: {type_manager.type_names.get(activity_type, activity_type)} ({activity_type})"
        )

        # å‘¨æœŸæ€§ç»Ÿè®¡
        weekly_stats = stats_analyzer.calculate_period_stats(
            activities, "weekly", activity_type
        )
        monthly_stats = stats_analyzer.calculate_period_stats(
            activities, "monthly", activity_type
        )
        yearly_stats = stats_analyzer.calculate_period_stats(
            activities, "yearly", activity_type
        )

        # è·ç¦»åˆ†å¸ƒ
        distance_dist = stats_analyzer.calculate_distance_distribution(
            activities, activity_type
        )

        # ä¸ªäººæœ€ä½³è®°å½•
        personal_bests = stats_analyzer.get_personal_bests(activities, activity_type)

        all_stats[activity_type] = {
            "weekly": weekly_stats,
            "monthly": monthly_stats,
            "yearly": yearly_stats,
            "distance_distribution": distance_dist,
            "personal_bests": personal_bests,
        }

    output_data = {
        "generated_at": datetime.now().isoformat(),
        "stats_by_type": all_stats,
    }

    # å†™å…¥åˆ°ä¸¤ä¸ªç›®å½•
    for output_dir in output_dirs:
        output_file = output_dir / "basic_statistics.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… åŸºç¡€ç»Ÿè®¡åˆ†æå·²ä¿å­˜åˆ°: {output_dirs[0]}")
    return all_stats


def generate_advanced_analysis(activities, output_dirs):
    """ç”Ÿæˆé«˜çº§åˆ†ææ•°æ®"""
    print("ğŸ”¬ ç”Ÿæˆé«˜çº§åˆ†ææ•°æ®...")

    type_manager = ActivityTypeManager()
    advanced_analyzer = AdvancedStatsAnalyzer()

    # è·å–å¯ç”¨çš„æ´»åŠ¨ç±»å‹
    available_types = ["all"] + type_manager.get_available_types(activities)
    print(f"  [DEBUG] å‘ç°çš„å¯ç”¨æ´»åŠ¨ç±»å‹: {available_types}")

    advanced_stats = {}

    for activity_type in available_types:
        # åªä¸ºè·‘æ­¥å’Œè¶Šé‡è·‘ç”Ÿæˆé«˜çº§åˆ†æ
        if activity_type in ["running", "trail_running", "all"]:
            print(
                f"  æ­£åœ¨åˆ†ææ´»åŠ¨ç±»å‹: {type_manager.type_names.get(activity_type, activity_type)} ({activity_type})"
            )

            # é…é€Ÿè¶‹åŠ¿åˆ†æ
            pace_trends = advanced_analyzer.analyze_pace_trends(
                activities, activity_type
            )

            advanced_stats[activity_type] = {"pace_trends": pace_trends}

    output_data = {
        "generated_at": datetime.now().isoformat(),
        "advanced_stats_by_type": advanced_stats,
    }

    # å†™å…¥åˆ°ä¸¤ä¸ªç›®å½•
    for output_dir in output_dirs:
        output_file = output_dir / "advanced_analysis.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… é«˜çº§åˆ†ææ•°æ®å·²ä¿å­˜åˆ°: {output_dirs[0]}")
    return advanced_stats


def generate_recent_summary(activities, output_dirs):
    """ç”Ÿæˆæœ€è¿‘æ´»åŠ¨æ‘˜è¦"""
    print("ğŸ“… ç”Ÿæˆæœ€è¿‘æ´»åŠ¨æ‘˜è¦...")

    stats_analyzer = BasicStatsAnalyzer()
    type_manager = ActivityTypeManager()

    available_types = ["all"] + type_manager.get_available_types(activities)

    summaries = {}

    for activity_type in available_types:
        # æœ€è¿‘7å¤©
        weekly_summary = stats_analyzer.calculate_period_stats(
            activities, "weekly", activity_type
        )

        # å½“æœˆ
        monthly_summary = stats_analyzer.calculate_period_stats(
            activities, "monthly", activity_type
        )

        # å½“å¹´
        yearly_summary = stats_analyzer.calculate_period_stats(
            activities, "yearly", activity_type
        )

        summaries[activity_type] = {
            "weekly": weekly_summary,
            "monthly": monthly_summary,
            "yearly": yearly_summary,
        }

    output_data = {
        "generated_at": datetime.now().isoformat(),
        "recent_summaries": summaries,
    }

    # å†™å…¥åˆ°ä¸¤ä¸ªç›®å½•
    for output_dir in output_dirs:
        output_file = output_dir / "recent_summary.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… æœ€è¿‘æ´»åŠ¨æ‘˜è¦å·²ä¿å­˜åˆ°: {output_dirs[0]}")
    return summaries


def generate_analysis_overview(activities, output_dirs):
    """ç”Ÿæˆåˆ†ææ¦‚è§ˆ"""
    print("ğŸ” ç”Ÿæˆåˆ†ææ¦‚è§ˆ...")

    type_manager = ActivityTypeManager()

    # åŸºæœ¬ä¿¡æ¯
    total_activities = len(activities)
    available_types = type_manager.get_available_types(activities)
    type_stats = type_manager.get_type_statistics(activities)

    # æ—¶é—´èŒƒå›´
    dates = []
    for activity in activities:
        date_str = activity.get("start_date_local", "")
        if date_str:
            try:
                if "T" in date_str:
                    date = datetime.fromisoformat(date_str.replace("Z", "+00:00"))
                else:
                    date = datetime.strptime(date_str, "%Y-%m-%d")
                dates.append(date)
            except:
                continue

    date_range = {}
    if dates:
        dates.sort()
        date_range = {
            "earliest": dates[0].strftime("%Y-%m-%d"),
            "latest": dates[-1].strftime("%Y-%m-%d"),
            "total_days": (dates[-1] - dates[0]).days + 1,
        }

    # æ€»ä½“ç»Ÿè®¡
    total_distance = sum(float(a.get("distance", 0)) for a in activities) / 1000
    total_time = sum(
        type_manager._parse_time(a.get("moving_time", "0")) for a in activities
    )

    overview = {
        "generated_at": datetime.now().isoformat(),
        "overview": {
            "total_activities": total_activities,
            "available_types": available_types,
            "total_distance_km": round(total_distance, 2),
            "total_time_seconds": total_time,
            "total_time_formatted": type_manager.format_time(total_time),
            "date_range": date_range,
            "avg_distance_per_activity": (
                round(total_distance / total_activities, 2)
                if total_activities > 0
                else 0
            ),
            "avg_time_per_activity": (
                type_manager.format_time(total_time // total_activities)
                if total_activities > 0
                else "0:00"
            ),
        },
        "type_breakdown": type_stats,
    }

    # å†™å…¥åˆ°ä¸¤ä¸ªç›®å½•
    for output_dir in output_dirs:
        output_file = output_dir / "analysis_overview.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(overview, f, ensure_ascii=False, indent=2)

    print(f"âœ… åˆ†ææ¦‚è§ˆå·²ä¿å­˜åˆ°: {output_dirs[0]}")
    return overview


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--type",
        dest="type",
        metavar="TYPE",
        default="all",
        help="è¦ç”Ÿæˆçš„åˆ†æç±»å‹ (e.g., all, running, cycling)",
    )
    args = parser.parse_args()

    print("ğŸš€ å¼€å§‹ç”Ÿæˆè¿åŠ¨æ•°æ®åˆ†æ...")
    print(f"ğŸ“Š åˆ†æç±»å‹: {args.type}")

    # ä¿®æ”¹ä¸ºç›´æ¥ä»JSONåŠ è½½
    activities = load_activities_from_json()
    if not activities:
        print("â—ï¸ æ²¡æœ‰åŠ è½½åˆ°æ´»åŠ¨æ•°æ®ï¼Œåˆ†æä¸­æ­¢ã€‚")
        return

    print(f"âœ… æˆåŠŸåŠ è½½ {len(activities)} æ¡æ´»åŠ¨è®°å½•")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dirs = ensure_output_dir()

    try:
        if args.type in ["all", "types"]:
            generate_activity_types(activities, output_dirs)

        if args.type in ["all", "basic"]:
            generate_basic_statistics(activities, output_dirs)

        if args.type in ["all", "advanced"]:
            generate_advanced_analysis(activities, output_dirs)

        if args.type in ["all", "summary"]:
            generate_recent_summary(activities, output_dirs)

        if args.type in ["all", "overview"]:
            generate_analysis_overview(activities, output_dirs)

        print("\nğŸ‰ æ‰€æœ‰åˆ†ææ•°æ®ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dirs[0]}")

        return 0

    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆåˆ†ææ•°æ®æ—¶å‡ºé”™: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
